{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtlaWNiPcggO"
      },
      "source": [
        "Cat Dog Classification\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gD7UF5HdcggP"
      },
      "outputs": [],
      "source": [
        "#importing the packages\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow 2.x equivalents\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Now you can access files in your Google Drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CM0DG3RgPA-",
        "outputId": "e9afa682-bdb5-44fb-f961-301c935f8bb6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5fPVQ_JcggQ"
      },
      "source": [
        "#### Define some mathematical functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "m6cRrYVecggQ"
      },
      "outputs": [],
      "source": [
        "# Here 0 means Cat and 1 means Dog\n",
        "CAT = 0\n",
        "DOG = 1\n",
        "#Returns whether the low memory mode is used.\n",
        "IS_LOW_MEMORY_MODE = True\n",
        "#current working directory of a process.\n",
        "cwd = os.getcwd()\n",
        "#This method is called when RandomState is initialized\n",
        "np.random.seed(2124)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "fCE9ys9XcggQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def prepare_file():\n",
        "    # Define paths to your files\n",
        "    cwd = '/content/drive/MyDrive/data'  # Update this path as needed\n",
        "    file_list = ['train', 'test']\n",
        "    flag = True\n",
        "\n",
        "    for file_name in file_list:\n",
        "        zip_filename = file_name + '.zip'\n",
        "        dest_filename = os.path.join(cwd, zip_filename)\n",
        "\n",
        "        if os.path.exists(dest_filename):\n",
        "            images_path = os.path.join(cwd, file_name)\n",
        "\n",
        "            with zipfile.ZipFile(dest_filename, 'r') as zip_ref:\n",
        "                zip_ref.extractall(images_path)\n",
        "                print(f'Extracted {zip_filename} to {images_path}')\n",
        "        else:\n",
        "            print(f'{zip_filename} does not exist in {cwd}')\n",
        "            flag = False\n",
        "\n",
        "    return flag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "jbfn0jgFcggR"
      },
      "outputs": [],
      "source": [
        "#Method to read the image label\n",
        "def read_image_label_list(folder_dir):\n",
        "    dir_list = os.listdir(os.path.join(cwd,folder_dir))\n",
        "    filenames = []\n",
        "    labels = []\n",
        "\n",
        "    for i, d in enumerate(dir_list):\n",
        "        if re.search(\"train\",folder_dir):\n",
        "            if re.search(\"cat\", d):\n",
        "                labels.append(CAT)\n",
        "            else:\n",
        "                labels.append(DOG)\n",
        "        else:\n",
        "            labels.append(-1)\n",
        "        filenames.append(os.path.join(cwd, folder_dir, d))\n",
        "    return filenames, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "ujam8gwscggR"
      },
      "outputs": [],
      "source": [
        "#Method to read the image from disk\n",
        "def read_images_from_disk(input_queue):\n",
        "    filename = input_queue[0]\n",
        "    label = input_queue[1]\n",
        "\n",
        "    file_contents = tf.read_file(filename)\n",
        "    image = tf.image.decode_image(file_contents, channels=3)\n",
        "    image.set_shape([None, None, 3])\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "Rnaee4ZFcggR"
      },
      "outputs": [],
      "source": [
        "#Method to generate input function\n",
        "def gen_input_fn(image_list, label_list, batch_size, shuffle):\n",
        "\n",
        "    def input_fn():\n",
        "        images = tf.convert_to_tensor(image_list, dtype=tf.string)\n",
        "        labels = tf.convert_to_tensor(label_list, dtype=tf.int32)\n",
        "\n",
        "        input_queue = tf.train.slice_input_producer(\n",
        "            [images, labels],\n",
        "            capacity=batch_size * 5,\n",
        "            shuffle=shuffle,\n",
        "            name=\"file_input_queue\"\n",
        "        )\n",
        "\n",
        "        image, label = read_images_from_disk(input_queue)\n",
        "        image = tf.image.resize_images(image, (224, 224), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "        image_batch, label_batch = tf.train.batch(\n",
        "            [image, label],\n",
        "            batch_size=batch_size,\n",
        "            num_threads=1,\n",
        "            name=\"batch_queue\",\n",
        "            capacity=batch_size * 10,\n",
        "            allow_smaller_final_batch = False\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            tf.identity(image_batch, name=\"features\"),\n",
        "            tf.identity(label_batch, name=\"label\")\n",
        "        )\n",
        "\n",
        "    return input_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "CM-79AJJcggR"
      },
      "outputs": [],
      "source": [
        "#Method to train a valid input function\n",
        "def train_valid_input_fn(data_dir, train_batch_size, valid_batch_size=None):\n",
        "    img, labels = read_image_label_list(data_dir)\n",
        "    img = np.array(img)\n",
        "    labels = np.array(labels)\n",
        "    data_size = img.shape[0]\n",
        "\n",
        "    print(\"Data size: \" + str(data_size))\n",
        "    split = int(0.7 * data_size)\n",
        "\n",
        "    random_seq = np.random.permutation(data_size)\n",
        "\n",
        "    img = img[random_seq]\n",
        "    labels = labels[random_seq]\n",
        "\n",
        "    if valid_batch_size == None:\n",
        "        valid_batch_size = train_batch_size\n",
        "\n",
        "    return (\n",
        "        gen_input_fn(img[0:split], labels[0:split], train_batch_size, shuffle = True),\n",
        "        gen_input_fn(img[split:], labels[split:], valid_batch_size, shuffle = False)\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "zImYnqkTcggS"
      },
      "outputs": [],
      "source": [
        "#Method to test input function\n",
        "def test_input_fn(data_dir,batch_size):\n",
        "    image_list, label_list = read_image_label_list(data_dir)\n",
        "    return gen_input_fn(image_list, label_list, batch_size, shuffle = False), image_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6_2u-BYcggS"
      },
      "source": [
        "### Data visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snumSsoFcggS",
        "outputId": "061a1a56-3f3c-4b95-a86a-ddbbc1f980bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted train.zip to /content/drive/MyDrive/data/train\n",
            "test.zip does not exist in /content/drive/MyDrive/data\n"
          ]
        }
      ],
      "source": [
        "if prepare_file():\n",
        "    print(\"Files completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "-J7QDR7-cggS"
      },
      "outputs": [],
      "source": [
        "#Method to plot data\n",
        "def plot_img(data, label=None):\n",
        "    plt.ion()\n",
        "    plt.figure()\n",
        "    plt.imshow(data)\n",
        "    if label is not None:\n",
        "        plt.title(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs3D6mETcggT",
        "outputId": "33f701ff-193c-4b3a-dfaf-a14328500502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Directory 'data/train' does not exist.\n"
          ]
        }
      ],
      "source": [
        "def plot_img(image, label):\n",
        "    plt.imshow(image)\n",
        "    plt.title(label)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def preview_img():\n",
        "    # Check current working directory\n",
        "    cwd = os.getcwd()\n",
        "    print(f\"Current working directory: {cwd}\")\n",
        "\n",
        "    # Verify the directory and file pattern\n",
        "    directory = 'data/train'\n",
        "    if os.path.exists(directory):\n",
        "        files = os.listdir(directory)\n",
        "        print(f\"Files in '{directory}': {files}\")\n",
        "    else:\n",
        "        print(f\"Directory '{directory}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Create a dataset with the correct file pattern\n",
        "    file_pattern = os.path.join(directory, '*.jpg')  # Ensure correct pattern\n",
        "    dataset = tf.data.Dataset.list_files(file_pattern)\n",
        "\n",
        "    def load_and_preprocess_image(filename):\n",
        "        image = tf.io.read_file(filename)\n",
        "        image = tf.image.decode_image(image, channels=3)  # Ensure 3 channels (RGB)\n",
        "        image = tf.image.resize(image, [224, 224])  # Resize image if needed\n",
        "        image = image / 255.0  # Normalize image\n",
        "        label = tf.strings.split(filename, '/')[-1]  # Extract label from filename\n",
        "        return image, label\n",
        "\n",
        "    dataset = dataset.map(load_and_preprocess_image)\n",
        "    dataset = dataset.batch(1)\n",
        "\n",
        "    for images, labels in dataset.take(5):  # Take 5 samples from the dataset\n",
        "        images = images.numpy()\n",
        "        labels = labels.numpy()\n",
        "        for i in range(len(images)):\n",
        "            plot_img(images[i], str(labels[i]))\n",
        "\n",
        "# Call the function to preview images\n",
        "preview_img()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6zPkw_lcggT"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "id": "tRLemtlncggT"
      },
      "outputs": [],
      "source": [
        "#Cat-Dog Method Declaration\n",
        "\n",
        "def catdog_model(inputs, is_training):\n",
        "    with tf.variable_scope('catdog', values=[inputs]):\n",
        "        with slim.arg_scope(\n",
        "            [slim.conv2d, slim.fully_connected],\n",
        "            activation_fn=tf.nn.relu6,\n",
        "            weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)):\n",
        "\n",
        "            net = inputs\n",
        "\n",
        "            if IS_LOW_MEMORY_MODE == False:\n",
        "                net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "\n",
        "                net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "\n",
        "                net = slim.repeat(net, 4, slim.conv2d, 256, [3, 3], scope='conv3')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
        "                net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv4')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
        "                net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv5')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
        "\n",
        "                net = tf.reshape(net, [-1, 7 * 7 * 512])\n",
        "\n",
        "                net = slim.fully_connected(net, 2048, scope='fc6')\n",
        "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout6')\n",
        "\n",
        "                net = slim.fully_connected(net, 2048, scope='fc7')\n",
        "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout7')\n",
        "\n",
        "                net = slim.fully_connected(net, 2, activation_fn=None, scope='fc8')\n",
        "\n",
        "            else:\n",
        "                # Model for my Mac T_T\n",
        "                net = tf.image.resize_images(net, (72, 72), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "                net = slim.repeat(net, 1, slim.conv2d, 64, [3, 3], scope='conv1')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "\n",
        "                net = slim.repeat(net, 1, slim.conv2d, 128, [3, 3], scope='conv2')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "\n",
        "                net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv3')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
        "\n",
        "                net = tf.reshape(net, [-1, 9 * 9 * 256])\n",
        "\n",
        "                net = slim.fully_connected(net, 1024, scope='fc4')\n",
        "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout4')\n",
        "\n",
        "                net = slim.fully_connected(net, 1024, scope='fc5')\n",
        "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout5')\n",
        "\n",
        "                net = slim.fully_connected(net, 2, activation_fn=None, scope='fc6')\n",
        "\n",
        "            return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "NtZIFm3VcggT"
      },
      "outputs": [],
      "source": [
        "#Cat-Dog Model function\n",
        "def catdog_model_fn(features, labels, mode, params):\n",
        "\n",
        "    is_training = False\n",
        "    if mode == learn.ModeKeys.TRAIN:\n",
        "        is_training = True\n",
        "\n",
        "    output = catdog_model(features, is_training)\n",
        "\n",
        "    log_loss = None\n",
        "    train_op = None\n",
        "    eval_metric_ops = None\n",
        "\n",
        "    softmax_predictions = tf.nn.softmax(output)\n",
        "\n",
        "    if mode != learn.ModeKeys.INFER:\n",
        "        onehot_labels = tf.one_hot(\n",
        "            tf.cast(labels, tf.int32),\n",
        "            depth = 2\n",
        "        )\n",
        "        log_loss = tf.identity(\n",
        "            tf.losses.log_loss(\n",
        "                onehot_labels,\n",
        "                tf.nn.softmax(output),\n",
        "                reduction = tf.losses.Reduction.MEAN\n",
        "            ),\n",
        "            name = \"log_loss_tensor\"\n",
        "        )\n",
        "        eval_metric_ops = {\n",
        "            \"log_loss\": log_loss\n",
        "        }\n",
        "\n",
        "    if mode == learn.ModeKeys.TRAIN:\n",
        "        train_op = tf.contrib.layers.optimize_loss(\n",
        "            loss = log_loss,\n",
        "            global_step = tf.contrib.framework.get_global_step(),\n",
        "            learning_rate = params['learning_rate'],\n",
        "            optimizer = \"Adam\"\n",
        "        )\n",
        "\n",
        "    predictions = {\n",
        "        'predict': softmax_predictions\n",
        "    }\n",
        "\n",
        "    return model_fn.ModelFnOps(\n",
        "        mode = mode,\n",
        "        predictions = predictions,\n",
        "        loss = log_loss,\n",
        "        train_op = train_op,\n",
        "        eval_metric_ops = eval_metric_ops\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "scrolled": false,
        "id": "fvCpwSwjcggT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model function for tf.estimator\n",
        "def catdog_model_fn(features, labels, mode, params):\n",
        "    # Extract the images from the features dictionary\n",
        "    images = features['image']\n",
        "\n",
        "    # Build the CNN model\n",
        "    net = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(images)\n",
        "    net = tf.keras.layers.MaxPooling2D((2, 2))(net)\n",
        "    net = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(net)\n",
        "    net = tf.keras.layers.MaxPooling2D((2, 2))(net)\n",
        "    net = tf.keras.layers.Flatten()(net)\n",
        "    net = tf.keras.layers.Dense(128, activation='relu')(net)\n",
        "    logits = tf.keras.layers.Dense(10)(net)  # Adjust output units as needed\n",
        "\n",
        "    predictions = {\n",
        "        'classes': tf.argmax(input=logits, axis=1),\n",
        "        'probabilities': tf.nn.softmax(logits)\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    # Loss function\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
        "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
        "    }\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhwEiHxQcggT"
      },
      "source": [
        "#### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "scrolled": false,
        "id": "L3FXAqD6cggT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import logging\n",
        "\n",
        "# Configure TensorFlow logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.INFO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6AK9VevacggU"
      },
      "outputs": [],
      "source": [
        "def catdog_model_fn(features, labels, mode, params):\n",
        "    images = features['image']\n",
        "\n",
        "    # Build the CNN model\n",
        "    net = tf.keras.layers.Input(shape=[224, 224, 3])(images)  # Adjust input shape\n",
        "    net = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(net)\n",
        "    net = tf.keras.layers.MaxPooling2D((2, 2))(net)\n",
        "    net = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(net)\n",
        "    net = tf.keras.layers.MaxPooling2D((2, 2))(net)\n",
        "    net = tf.keras.layers.Flatten()(net)\n",
        "    net = tf.keras.layers.Dense(128, activation='relu')(net)\n",
        "    logits = tf.keras.layers.Dense(10)(net)  # Adjust output units as needed\n",
        "\n",
        "    predictions = {\n",
        "        'classes': tf.argmax(input=logits, axis=1),\n",
        "        'probabilities': tf.nn.softmax(logits)\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    # Loss function\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
        "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
        "    }\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W75g9UT7cggU"
      },
      "source": [
        "#### Final Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBB2QyTscggU",
        "outputId": "ae6b8152-8c77-4d0f-905c-d40b57137b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test directory '/content/data' does not exist.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the path to your test directory\n",
        "test_data_dir = '/content/data'  # Adjust this path if needed\n",
        "\n",
        "# Check if the test directory exists\n",
        "if not os.path.exists(test_data_dir):\n",
        "    print(f\"Test directory '{test_data_dir}' does not exist.\")\n",
        "else:\n",
        "    # Proceed with your test input function\n",
        "    test_fn, image_test_list = test_input_fn(test_data_dir, 32)\n",
        "    test_n = len(image_test_list)\n",
        "\n",
        "    print(\"Test size: %d\" % test_n)\n",
        "\n",
        "    # Create the result directory if it doesn't exist\n",
        "    result_path = os.path.join(cwd, 'result/result.txt')\n",
        "    os.makedirs(os.path.dirname(result_path), exist_ok=True)\n",
        "\n",
        "    with open(result_path, 'w+') as result_file:\n",
        "        result_file.write('id,label\\n')\n",
        "\n",
        "        predictions = classifier.predict(input_fn=test_fn, as_iterable=True)\n",
        "        for i, p in enumerate(predictions):\n",
        "            if i >= test_n:\n",
        "                break\n",
        "\n",
        "            id = image_test_list[i].split(\"/\")[-1]\n",
        "            id = id.split(\".\")[0]\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(\"Predict %d %s: %f\" % (i, image_test_list[i], p[\"probabilities\"][1]))\n",
        "\n",
        "            result_file.write(\"%s,%f\\n\" % (id, p[\"probabilities\"][1]))\n",
        "\n",
        "    print('Finish!!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-YVNJmjxcggU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}